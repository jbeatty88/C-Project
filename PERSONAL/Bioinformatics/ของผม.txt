Objective: Identify sample origin location

Inventory:
	-16S sequencing-based OTU's for thousands of soil samples 
	-Hundreds of samples with WGS raw reads from urban locations from MetaSub Consortium

Relevant Terms:
	 Metagenomics: The study of genetic material recovered directly from environmental samples.
	 
	 16S rRNA: The component of the 30S small subunit of a prokaryotic ribosome that binds to the Shine-Dalgarno sequence. Used in reconstructin phylogenies. "Reliable molecular clock."
	 
	 Single Nucleotide Polymorphism (SNP): Variation in a single nucleotide that occurs at a specific position in the genome,
	 		   		       where each variation is present to some appreciable degree within a population
	 
	 Single Nucleotide Variant (SNV): Variation in a single nucleotide without any limitations of frequency and may arise in somatic cells.
	 
	 Bootstrapping: Using the accessible data to infer the uncertainty of the data by sampling or permutating the input data.
	 
	 .fastq: Text-based format used for storing a biological sequence and its corresponding quality scores.
	 	 LOW--  !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~ --HIGH
	 
	 Phred Quality Score: Measure of the quality of the identification of the nucleobases generated by automated DNA sequencing.
	       	       	      Assigned to each nucleotide base call. Encoded as ASCII chars alongside the reads in FASTQ format.

	 Operational Taxonomic Unit (OTU): Operational definition used to classify groups of closely related individuals. Clusters of organisms,
	 	     	       	    	   grouped by DNA sequence similarity of a specific taxonomic marker gene.
					   
	 Whole Genome Shotgun (WGS): Genome assemblies of incomplete genomes or incomplete chromosomes of prokaryotes or eukaryontes that are
	       	      	      	     generally being sequenced by a while genome shotgun strategy.

	 Shotgun Sequencing: Longer sequences are subdivided into smaller random fragments that can be sequenced separately, and these sequences
	 	 	     are assembled to give the overall sequence. Sequenced using the Chain-Termination Method to obtain reads; Multiple
			     overlapping reads for the target DNA are obtained by perfoming more rounds of random fragmentation and
			     sequencing. Computer programs use the overlapping ends of different reads to assemble them into a continuous
			     sequence.
	 
			      
Examples:
	SNP: At a specific base position in the human genome, the C nucleotide might appear in most people but in a minority,
	     that same position is the A nucleotide. This would mean that there is a "SNP" at this position.
	     The two possible nucleotide variations-- C or A -- are said to be alleles for this position.
	
	Phred Score: [Qscore - Probability of incorrect base call] | 10 - 1 in 10 | 20 - 1 in 100 | 30 - 1 in 1000 | 40 - 1 in 10,000 |
	      	     50 - 1 in 100,000 | 60 - 1 in 1,000,000. Used for assesment of sequence quality, recognition and removal of low-quality sequences (End Clipping)

Tools:




Steps:
	1) Quality Control using bbduk
	   - This is actually very rough for me; most of these concepts are extremely new and I still don't completely know what is meant by
	   'Quality Control' but the answer I got from a reddit user on r/bioinformatics was:
	   
		"bbduk is mainly used for trimming, of both the adapter and quality varieties.

	   	I am not sure you can do quality recalibration on metagenomic samples as you
	   	won't have a reference or a list of SNPs to use.
	   	You probably can't bootstrap it either because your coverage is all over the
       	  	place (per species), and microbes mutate a lot faster than humans, so it'd be
	   	really hard to tell a machine error vs a true SNV.

	   	I would guess that quality control in this case just means that the majority of
	   	the base pair data in your fastq is genomic in origin and not adapters or low
	   	quality tails. You could try trimming at various phred score cutoffs and see how
	   	sharply your sample drops off usable bases vs any "gold standard" sample your
	   	lab has of the same sample type and library-prep/sequencing protocol. You can also
	   	check that the insert sizes are relatively uniform across all samples, and at least
	   	within the expected parameters.

	   	Good luck!

     	   	PS I don't think you can run stats.sh on a fastq since it's meant to be run against
	   	assemblies. That's why you have an N50 of 151bp and 39 million scaffolds. If I am
	   	intepreting it correctly, it also looks like you have 0.003% of reads with at least
	   	1 non-terminal N?"
